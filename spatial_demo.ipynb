{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial queries in duckdb using jinja and magic_duckdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links: <br> https://pypi.org/project/magic-duckdb/<br> \n",
    "https://duckdb.org/<br>\n",
    "#### GitHub:<br>\n",
    "https://github.com/RandomFractals/geo-data-viewer/tree/master/data/csv\n",
    "https://github.com/Tor-Storli/Geospatial_Data/tree/main/data<br>\n",
    "#### Tor-Storli-YouTube:<br>\n",
    "https://youtu.be/hMP-LGju1IA<br>\n",
    "https://youtu.be/zoUcuJbGCp0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If needed you can change the fonts like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "    body {\n",
    "        --vscode-font-family: \"Arial\";\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python Libraries and add a reference to the magic_duckdb package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as duckdb\n",
    "import magic_duckdb\n",
    "import pandas as pd\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "%load_ext magic_duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install and load the duckdb spatial and httpfs extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql \n",
    "-- INSTALL spatial;\n",
    "-- INSTALL httpfs;\n",
    "LOAD spatial;\n",
    "LOAD httpfs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query data from GeoJson file over the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%dql -t show\n",
    "SELECT * FROM 'https://raw.githubusercontent.com/Tor-Storli/Geospatial_Data/main/data/IL_Counties_Census.json' LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the your current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a local GeoJson file from the GeoJson file located on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%%dql\n",
    "COPY (SELECT * FROM 'https://raw.githubusercontent.com/Tor-Storli/Geospatial_Data/main/data/IL_Counties_Census.json')\n",
    "      TO 'IL_Counties_Census.json' (FORMAT 'json');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using jinja2 python library in magic_duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JINJA Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can use jinja2 text templating language library to make dynamic queries. <br> You can find out more about it here: <br> https://codeburst.io/jinja-2-explained-in-5-minutes-88548486834e  <br> https://jinja.palletsprojects.com/en/2.11.x/templates/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples: <br> ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create some sample data and load into a pandas dataframe ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace with your actual data)\n",
    "data = {\n",
    "    'dates': ['2024-03-12', '2024-03-13','2024-03-14', '2024-03-15', '2024-03-16'],\n",
    "    'distances': ['5K', '3K', '3K', '3K', '5k']\n",
    "}\n",
    "df_Runs = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic dynamic sort query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_column = 'dates'\n",
    "sort_direction = 'Asc'\n",
    "%dql --jinja2 SELECT * FROM df_Runs ORDER BY {{ sort_column }} {{ sort_direction }};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us inspect the datatypes in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Runs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert dates column to a timestamp datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Runs['dates'] = pd.to_datetime(df_Runs['dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Runs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a pivot query using jinja2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explanation:\n",
    "- We use a `{%- for run_type in run_types %}` loop to iterate through the list of run types types.\n",
    "- For each run type, we create a conditional aggregation using a CASE statement:<br>`SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END`.\n",
    "- The `tot_{{ distance }}` alias represents the total count for that run distance type.\n",
    "- The `GROUP BY 1` groups the results by the first column in our query - the `dates` column.\n",
    "- Finally, we order the results by date in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the SQL query dynamically using Jinja2-like template\n",
    "run_types = ['5K', '3K']\n",
    "\n",
    "jinja2_pivot_query = \"\"\"\n",
    "SELECT dates,\n",
    "    {%- for run_type in run_types %}\n",
    "    SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END) AS tot_{{ run_type }}\n",
    "    {%- if not loop.last -%}, {% endif -%}\n",
    "    {%- endfor %}\n",
    "FROM df_Runs\n",
    "GROUP BY 1\n",
    "ORDER BY 1 ASC;\n",
    "\"\"\"\n",
    "print(jinja2_pivot_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the query from above and run it using magic_duckdb and jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql --jinja2 -t df\n",
    "\n",
    "SELECT dates,\n",
    "    {%- for run_type in run_types %}\n",
    "    SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END) AS tot_{{ run_type }}\n",
    "    {%- if not loop.last -%}, {% endif -%}\n",
    "    {%- endfor %}\n",
    "FROM df_Runs\n",
    "GROUP BY 1\n",
    "ORDER BY 1 ASC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also extract the week from the dates so we calculate the total distances we ran that week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql --jinja2 -t df\n",
    "SELECT date_part('week', dates) as week,\n",
    "    {%- for run_type in run_types %}\n",
    "    SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END) AS tot_{{ run_type }} \n",
    "    {%- if not loop.last -%}, {% endif -%}\n",
    "    {%- endfor %}\n",
    "FROM df_Runs\n",
    "GROUP BY 1\n",
    "ORDER BY 1 ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using regular duckdb Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql -t df\n",
    "SELECT dates,\n",
    "    SUM(CASE WHEN distances = '5K' THEN 1 ELSE 0 END) AS num_5K,\n",
    "    SUM(CASE WHEN distances = '3K' THEN 1 ELSE 0 END) AS num_3K\n",
    "FROM df_Runs\n",
    "GROUP BY dates;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The problem starts when we add more distances. <br>We then have to keep adding distances to the queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So let us create a more elegant way of running queries dynamically,<br> we use pandas, jinja2, and magic_duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace with your actual data)\n",
    "data = {\n",
    "    'dates': ['2024-03-12', '2024-03-13','2024-03-14', \n",
    "              '2024-03-15', '2024-03-16','2024-03-17',\n",
    "              '2024-03-18', '2024-03-19', '2024-03-20'],\n",
    "    'distances': ['5K', '3K', '3K', '3K', '5K', '7K','10K', '7K','5K']\n",
    "}\n",
    "df_Runs = pd.DataFrame(data)\n",
    "df_Runs['dates'] = pd.to_datetime(df_Runs['dates'])\n",
    "df_Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dynamic run_type list containing unique distance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_types =  df_Runs['distances'].unique()\n",
    "run_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql --jinja2 -t df\n",
    "SELECT dates,\n",
    "    {%- for run_type in run_types %}\n",
    "    SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END) AS tot_{{ run_type }}\n",
    "    {%- if not loop.last -%}, {% endif -%}\n",
    "    {%- endfor %}\n",
    "FROM df_Runs\n",
    "GROUP BY 1\n",
    "ORDER BY 1 ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total each distance for the two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql --jinja2 -t df\n",
    "SELECT date_part('week', dates) as week,\n",
    "    {%- for run_type in run_types %}\n",
    "    SUM(CASE WHEN distances = '{{ run_type }}' THEN 1 ELSE 0 END) AS tot_{{ run_type }}\n",
    "    {%- if not loop.last -%}, {% endif -%}\n",
    "    {%- endfor %}\n",
    "FROM df_Runs\n",
    "GROUP BY 1\n",
    "ORDER BY 1 ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us use jinja and retrieve a GeoJson file from Github and save a copy to our current local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://raw.githubusercontent.com/Tor-Storli/Geospatial_Data/main/data/\"\n",
    "cafile = \"CA_Counties_Census.json\"\n",
    "jsonformat = \"JSON\"\n",
    "csvformat = \"CSV, DELIMITER '|', HEADER\"\n",
    "print()\n",
    "%dql --jinja2 COPY (SELECT * FROM '{{baseurl}}{{cafile}}') TO '{{cafile}}' (FORMAT {{jsonformat}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all `json` and `csv` files that are in the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "currdir = os.getcwd() \n",
    "\n",
    "filelist = [ f for f in os.listdir(currdir) if f.endswith(\".json\") or f.endswith(\".csv\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(currdir, f))\n",
    "    print('deleting file: ' + f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us use jinja and retrieve several GeoJson files and a csv file from Github<br> and save a copies to our current local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create a utility function that returns the format\n",
    "def get_format(filename):\n",
    "    extension = file.split('.')[1]\n",
    "    jsonformat = \"JSON\"\n",
    "    csvformat = \"CSV, DELIMITER '|', HEADER\"\n",
    "    if extension == \"json\":\n",
    "        return jsonformat\n",
    "    if extension == \"csv\":\n",
    "        return csvformat\n",
    "    \n",
    "# Set up file list for download\n",
    "baseurl = \"https://raw.githubusercontent.com/Tor-Storli/Geospatial_Data/main/data/\"\n",
    "files = [\"CA_Counties_Census.json\", \"IL_Counties_Census.json\", \"us_food_restaurants.json\", \"targets.csv\"]\n",
    "#files = [\"targets.csv\"]\n",
    "jsonformat = \"JSON\"\n",
    "csvformat = \"CSV, DELIMITER '|', HEADER\"\n",
    "    \n",
    "    \n",
    "# iterate file list using for loop\n",
    "for file in files:\n",
    "    fileformat = get_format(file)\n",
    "    %dql --jinja2 COPY (SELECT * FROM '{{baseurl}}{{file}}') TO '{{file}}' (FORMAT {{fileformat}});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize spatial data with Keppler Map View Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Counties spatial data in Map View "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us download airport data from GitHub and save it locally as a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "#import pandas as pd\n",
    "#from lxml import html\n",
    "\n",
    "# Define the Wikipedia URL\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_airports_in_Illinois\"\n",
    "\n",
    "# Define the XPath expression for the table\n",
    "xpath_expression = '//*[@id=\"mw-content-text\"]/div[1]/table'\n",
    "#xpath_expression = '//*[@id=\"mw-content-text\"]/div[1]/table/tbody'\n",
    "\n",
    "# Send an HTTP request to the Wikipedia page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using lxml\n",
    "tree = html.fromstring(response.content)\n",
    "\n",
    "# Find the table using the XPath expression\n",
    "table = tree.xpath(xpath_expression)[0]\n",
    "\n",
    "#print(table)\n",
    "# Convert the table to a Pandas DataFrame\n",
    "df_wiki = pd.read_html(html.tostring(table))[0]\n",
    "\n",
    "df_wiki.dropna(inplace=True)\n",
    "\n",
    "# remove all records that do not have FAA numbers\n",
    "#df_csv = df_wiki.drop(index=1)\n",
    "\n",
    "#print(df_wiki.head())\n",
    "# Save the DataFrame to a CSV file\n",
    "df_wiki.to_csv(\"wiki_il_airport_data.csv\", index=False)\n",
    "\n",
    "# Print a success message\n",
    "print(\"Illinois airport data from wikipedia has been downloaded and saved as wiki_il_airport_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a data frame from the GeoJson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open(\"usa-airports.map.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Extract the \"allData\" array\n",
    "all_data = data[\"datasets\"][0][\"data\"][\"allData\"]\n",
    "\n",
    "# Define column names and data types\n",
    "columns = [\"iata\", \"name\", \"city\", \"state\", \"country\", \"latitude\", \"longitude\"]\n",
    "data_types = {\n",
    "    \"iata\": \"str\",\n",
    "    \"name\": \"str\",\n",
    "    \"city\": \"str\",\n",
    "    \"state\": \"str\",\n",
    "    \"country\": \"str\",\n",
    "    \"latitude\": \"float\",\n",
    "    \"longitude\": \"float\"\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df_usair = pd.DataFrame(all_data, columns=columns)\n",
    "df_usair.dropna(inplace=True)\n",
    "\n",
    "# Convert data types\n",
    "for col, dtype in data_types.items():\n",
    "    df_usair[col] = df_usair[col].astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql -t df -o df_wiki\n",
    "SELECT \"City served\" as City,\n",
    "        FAA,\n",
    "        IATA,\n",
    "        \"Airport name\" As Airport,\n",
    "        Role,\n",
    "        \"Enplanements (2019)\" As Passengers\n",
    "FROM read_csv_auto('wiki_il_airport_data.csv', Header=TRUE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_usair, df_wiki, left_on='iata', right_on='FAA')\n",
    "\n",
    "merged_df.drop(columns=['City'], inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE WIKI_US_AIRPORTS AS \n",
    "SELECT iata,name,city,state,country,FAA,Airport,Role,Passengers, \n",
    "       ST_Point(longitude, latitude) AS Geometry\n",
    "FROM merged_df;     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql \n",
    "COPY WIKI_US_AIRPORTS TO 'wiki_us_airports.geojson' WITH (FORMAT GDAL, DRIVER 'GeoJson') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us create a new table based on the California Counties GeoJson file. <br>We can use the flexible `ST_Read()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE CA_Counties AS SELECT * FROM ST_Read('CA_Counties_Census.json');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us use the `ST_Union_Agg()` aggregate function and combine a few counties into one shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql\n",
    "CREATE OR REPLACE TABLE CA_Counties_Agg AS\n",
    "SELECT ST_Union_Agg(\"geom\") as geoAgg FROM 'CA_Counties' \n",
    "WHERE id in(6015, 6093,6049,4445,6023,6105,6089,6035)\n",
    "GROUP BY id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us now save the new aggregated shape file to our local folder and view it on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dql\n",
    "COPY CA_Counties_Agg TO 'CA_Counties_Agg.geojson' WITH (FORMAT GDAL, DRIVER 'GeoJson') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
